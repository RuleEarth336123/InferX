
# Consider dependencies only in project.
set(CMAKE_DEPENDS_IN_PROJECT_ONLY OFF)

# The set of languages for which implicit dependencies are needed:
set(CMAKE_DEPENDS_LANGUAGES
  )

# The set of dependency files which are needed:
set(CMAKE_DEPENDS_DEPENDENCY_FILES
  "/home/chunyu123/github/InferX/kernels/cpu/add_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/add_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/add_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/emb_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/emb_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/emb_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/matmul_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/matmul_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/matmul_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/mha_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/mha_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/mha_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/rmsnorm_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/rmsnorm_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/rmsnorm_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/rope_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/rope_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/rope_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/scale_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/scale_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/scale_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/softmax_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/softmax_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/softmax_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/cpu/swiglu_kernel.cpp" "CMakeFiles/llama.dir/kernels/cpu/swiglu_kernel.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/cpu/swiglu_kernel.cpp.o.d"
  "/home/chunyu123/github/InferX/kernels/kernel_interface.cpp" "CMakeFiles/llama.dir/kernels/kernel_interface.cpp.o" "gcc" "CMakeFiles/llama.dir/kernels/kernel_interface.cpp.o.d"
  "/home/chunyu123/github/InferX/src/base/alloc.cpp" "CMakeFiles/llama.dir/src/base/alloc.cpp.o" "gcc" "CMakeFiles/llama.dir/src/base/alloc.cpp.o.d"
  "/home/chunyu123/github/InferX/src/base/base.cpp" "CMakeFiles/llama.dir/src/base/base.cpp.o" "gcc" "CMakeFiles/llama.dir/src/base/base.cpp.o.d"
  "/home/chunyu123/github/InferX/src/base/buffer.cpp" "CMakeFiles/llama.dir/src/base/buffer.cpp.o" "gcc" "CMakeFiles/llama.dir/src/base/buffer.cpp.o.d"
  "/home/chunyu123/github/InferX/src/op/add.cpp" "CMakeFiles/llama.dir/src/op/add.cpp.o" "gcc" "CMakeFiles/llama.dir/src/op/add.cpp.o.d"
  "/home/chunyu123/github/InferX/src/op/layer.cpp" "CMakeFiles/llama.dir/src/op/layer.cpp.o" "gcc" "CMakeFiles/llama.dir/src/op/layer.cpp.o.d"
  "/home/chunyu123/github/InferX/src/tensor/tensor.cpp" "CMakeFiles/llama.dir/src/tensor/tensor.cpp.o" "gcc" "CMakeFiles/llama.dir/src/tensor/tensor.cpp.o.d"
  )

# Targets to which this target links.
set(CMAKE_TARGET_LINKED_INFO_FILES
  )

# Fortran module output directory.
set(CMAKE_Fortran_TARGET_MODULE_DIR "")
